{
  "6": {
    "inputs": {
      "text": "A stylish and elegant Blonde with a model-like figure, dressed in a professional yet fashionable outfit, such as a tailored blazer, slim-fit trousers, and classic heels. She has a confident and warm expression, carrying a sleek leather briefcase, walking in a modern urban setting. Soft natural lighting, realistic details, and a sophisticated atmosphere",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "44",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "13",
        0
      ],
      "vae": [
        "10",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAEè§£ç "
    }
  },
  "10": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "åŠ è½½VAE"
    }
  },
  "13": {
    "inputs": {
      "noise": [
        "25",
        0
      ],
      "guider": [
        "22",
        0
      ],
      "sampler": [
        "16",
        0
      ],
      "sigmas": [
        "17",
        0
      ],
      "latent_image": [
        "68",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "è‡ªå®šä¹‰é‡‡æ ·å™¨ï¼ˆé«˜çº§ï¼‰"
    }
  },
  "16": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "Ké‡‡æ ·å™¨é€‰æ‹©"
    }
  },
  "17": {
    "inputs": {
      "scheduler": "simple",
      "steps": 20,
      "denoise": 1,
      "model": [
        "30",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "åŸºæœ¬è°ƒåº¦å™¨"
    }
  },
  "22": {
    "inputs": {
      "model": [
        "30",
        0
      ],
      "conditioning": [
        "26",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "åŸºæœ¬å¼•å¯¼å™¨"
    }
  },
  "25": {
    "inputs": {
      "noise_seed": 102025857031146
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "éšæœºå™ªæ³¢"
    }
  },
  "26": {
    "inputs": {
      "guidance": 3.500000000000001,
      "conditioning": [
        "6",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "Fluxå¼•å¯¼"
    }
  },
  "27": {
    "inputs": {
      "width": [
        "66",
        0
      ],
      "height": [
        "67",
        0
      ],
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "ç©ºLatentå›¾åƒï¼ˆSD3ï¼‰"
    }
  },
  "30": {
    "inputs": {
      "max_shift": 1.1500000000000001,
      "base_shift": 0.5000000000000001,
      "width": [
        "66",
        0
      ],
      "height": [
        "67",
        0
      ],
      "model": [
        "47",
        0
      ]
    },
    "class_type": "ModelSamplingFlux",
    "_meta": {
      "title": "é‡‡æ ·ç®—æ³•ï¼ˆFluxï¼‰"
    }
  },
  "44": {
    "inputs": {
      "model_type": "flux",
      "text_encoder1": "t5xxl_fp16.safetensors",
      "text_encoder2": "clip_l.safetensors",
      "t5_min_length": 512,
      "use_4bit_t5": "disable",
      "int4_model": "none"
    },
    "class_type": "NunchakuTextEncoderLoader",
    "_meta": {
      "title": "Nunchaku Text Encoder Loader"
    }
  },
  "45": {
    "inputs": {
      "model_path": "svdq-int4-flux.1-dev",
      "cache_threshold": 0,
      "attention": "nunchaku-fp16",
      "cpu_offload": "auto",
      "device_id": 0,
      "data_type": "bfloat16",
      "i2f_mode": "enabled"
    },
    "class_type": "NunchakuFluxDiTLoader",
    "_meta": {
      "title": "Nunchaku FLUX DiT Loader"
    }
  },
  "47": {
    "inputs": {
      "lora_name": "flux/f1-details.safetensors",
      "lora_strength": 0.30000000000000004,
      "model": [
        "69",
        0
      ]
    },
    "class_type": "NunchakuFluxLoraLoader",
    "_meta": {
      "title": "Nunchaku FLUX.1 LoRA Loader"
    }
  },
  "49": {
    "inputs": {
      "filename_prefix": "qihuaoutput",
      "with_workflow": false,
      "metadata_extra": "{\n  \"Title\": \"Image generated by qihuaimage\",\n  \"Description\": \"More info: www.qihuaimage.com\"\n}",
      "image": [
        "8",
        0
      ]
    },
    "class_type": "Save image with extra metadata [Crystools]",
    "_meta": {
      "title": "ğŸª› Save image with extra metadata"
    }
  },
  "64": {
    "inputs": {
      "anything": [
        "8",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "æ¸…ç†æ˜¾å­˜å ç”¨"
    }
  },
  "66": {
    "inputs": {
      "value": 1024
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "å®½"
    }
  },
  "67": {
    "inputs": {
      "value": 1538
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "é«˜"
    }
  },
  "68": {
    "inputs": {
      "batch_size": 1,
      "latents": [
        "27",
        0
      ]
    },
    "class_type": "RebatchLatents",
    "_meta": {
      "title": "é‡è®¾Latentæ‰¹æ¬¡"
    }
  },
  "69": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "45",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  }
}